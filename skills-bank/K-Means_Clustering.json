{"category":{"id":[3],"name":["Analysis"]},"description":["k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances, but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids."],"descriptionSource":["https://en.wikipedia.org/wiki/K-means_clustering"],"id":["KSYCVNF7JZ2WR6LZUF9O"],"infoUrl":["https://skills.emsidata.com/skills/KSYCVNF7JZ2WR6LZUF9O"],"isLanguage":[false],"isSoftware":[false],"name":["K-Means Clustering"],"removedDescription":{},"subcategory":{"id":[118],"name":["Data Science"]},"tags":[{"key":["wikipediaExtract"],"value":["k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances, but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids."]},{"key":["wikipediaUrl"],"value":["https://en.wikipedia.org/wiki/K-means_clustering"]}],"type":{"id":["ST1"],"name":["Specialized Skill"]}}
